{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.blackscholes import *\n",
    "from src.pinn import *\n",
    "from src.collocation import *\n",
    "from src.differential import BlackScholesDifferential\n",
    "from src.differential import SchrodingerDifferential\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_44994/437918939.py:20: UserWarning: Parsing dates in %Y-%m-%d %H:%M:%S format when dayfirst=True was specified. Pass `dayfirst=False` or specify a format to silence this warning.\n",
      "  df = pd.read_csv(file_path, parse_dates=['Timestamp'], dayfirst=True)\n",
      "/tmp/ipykernel_44994/437918939.py:21: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df['logS'] = np.log(df['LTP'].replace(0, np.nan)).fillna(method='ffill')\n",
      "/tmp/ipykernel_44994/437918939.py:22: UserWarning: Parsing dates in %Y-%m-%d format when dayfirst=True was specified. Pass `dayfirst=False` or specify a format to silence this warning.\n",
      "  df['TimeToMaturity'] = (pd.to_datetime(df['ExpiryDate'], dayfirst=True) - df['Timestamp']).dt.total_seconds()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Saved MAT file: /mnt/c/Meril/Python/1D_BS_SE_pinn-black-scholes-main/PINN_TRAIN_DATA.mat\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import os\n",
    "from datetime import datetime\n",
    "from scipy.interpolate import griddata\n",
    "from pathlib import Path\n",
    "\n",
    "# ---------- CONFIG ----------\n",
    "# Use current working directory\n",
    "DATA_DIR = Path.cwd()\n",
    "OPT_TRAIN_FILE = DATA_DIR / 'OPT_RELIANCE_20250529.csv'\n",
    "OPT_TEST_FILE  = DATA_DIR / 'OPT_RELIANCE_20250626.csv'\n",
    "EQT_TRAIN_FILE = DATA_DIR / 'EQT_RELIANCE_20250529.csv'\n",
    "EQT_TEST_FILE  = DATA_DIR / 'EQT_RELIANCE_20250626.csv'\n",
    "OUTPUT_MAT_FILE = DATA_DIR / 'PINN_TRAIN_DATA.mat'\n",
    "\n",
    "# ---------- HELPERS ----------\n",
    "def load_data(file_path):\n",
    "    df = pd.read_csv(file_path, parse_dates=['Timestamp'], dayfirst=True)\n",
    "    df['logS'] = np.log(df['LTP'].replace(0, np.nan)).fillna(method='ffill')\n",
    "    df['TimeToMaturity'] = (pd.to_datetime(df['ExpiryDate'], dayfirst=True) - df['Timestamp']).dt.total_seconds()\n",
    "    df['TimeToMaturity'] = df['TimeToMaturity'] / df['TimeToMaturity'].max()  # Normalize [0,1]\n",
    "    df['MidPrice'] = (df['BuyPrice'] + df['SellPrice']) / 2\n",
    "    df['Spread'] = df['SellPrice'] - df['BuyPrice']\n",
    "    df['Imbalance'] = (df['BuyQty'] - df['SellQty']) / (df['BuyQty'] + df['SellQty'] + 1e-5)\n",
    "    df['EntropicVol'] = df['LTP'].pct_change().rolling(5).std().fillna(0)\n",
    "    df['LogReturn'] = np.log(df['LTP'] / df['LTP'].shift(1)).fillna(0)\n",
    "    df['Entropy'] = (df['LogReturn']**2).rolling(5).mean().fillna(0)\n",
    "    df['RegimeFlag'] = ((df['LogReturn'].abs() > 0.01) | (df['Entropy'] > 0.0005)).astype(int)  # volatility/gap flag\n",
    "    df['Delta'] = 0.5  # Placeholder for simplicity\n",
    "    df['IV'] = df['Spread'] / (df['LTP'] + 1e-5)  # Crude IV proxy\n",
    "\n",
    "    return df\n",
    "\n",
    "# ---------- MAIN ----------\n",
    "def main():\n",
    "    opt_df = load_data(OPT_TRAIN_FILE)\n",
    "\n",
    "    x = opt_df['logS'].values\n",
    "    t = opt_df['TimeToMaturity'].values\n",
    "    re_psi = opt_df['LTP'].values\n",
    "    im_psi = opt_df['Imbalance'].values * opt_df['Spread'].values\n",
    "\n",
    "    uu = re_psi + 1j * im_psi\n",
    "\n",
    "    # Engineered features\n",
    "    feature_dict = {\n",
    "        'IV': opt_df['IV'].values,\n",
    "        'Delta': opt_df['Delta'].values,\n",
    "        'OI': opt_df['OpenInterest'].values,\n",
    "        'Entropy': opt_df['Entropy'].values,\n",
    "        'RegimeFlag': opt_df['RegimeFlag'].values\n",
    "    }\n",
    "\n",
    "    # Create mesh grid for interpolation\n",
    "    x_grid = np.linspace(np.min(x), np.max(x), 256)\n",
    "    t_grid = np.linspace(np.min(t), np.max(t), 100)\n",
    "    x_mesh, t_mesh = np.meshgrid(x_grid, t_grid)\n",
    "    uu_grid = griddata((x, t), uu, (x_mesh, t_mesh), method='linear', fill_value=0)\n",
    "\n",
    "    # Interpolate features\n",
    "    feature_grids = {}\n",
    "    for name, feat in feature_dict.items():\n",
    "        feature_grids[name] = griddata((x, t), feat, (x_mesh, t_mesh), method='linear', fill_value=0)\n",
    "\n",
    "    # Final output dict\n",
    "    output = {\n",
    "        'x': x_grid,\n",
    "        'tt': t_grid,\n",
    "        'uu': uu_grid,\n",
    "    }\n",
    "    for name, grid in feature_grids.items():\n",
    "        output[name] = grid\n",
    "\n",
    "    # Save to .mat\n",
    "    sio.savemat(OUTPUT_MAT_FILE, output)\n",
    "    print(f\" Saved MAT file: {OUTPUT_MAT_FILE}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_44994/1172055242.py:12: UserWarning: Parsing dates in %Y-%m-%d %H:%M:%S format when dayfirst=True was specified. Pass `dayfirst=False` or specify a format to silence this warning.\n",
      "  df = pd.read_csv(file_path, parse_dates=['Timestamp'], dayfirst=True)\n",
      "/tmp/ipykernel_44994/1172055242.py:13: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df['logS'] = np.log(df['LTP'].replace(0, np.nan)).fillna(method='ffill')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".mat file saved: /mnt/c/Meril/Python/1D_BS_SE_pinn-black-scholes-main/EQT_PINN_TRAIN_DATA.mat\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "from pathlib import Path\n",
    "from scipy.interpolate import griddata\n",
    "\n",
    "DATA_DIR = Path.cwd()\n",
    "EQT_TRAIN_FILE = DATA_DIR / 'EQT_RELIANCE_20250529.csv'\n",
    "EQT_OUTPUT_MAT_FILE = DATA_DIR / 'EQT_PINN_TRAIN_DATA.mat'\n",
    "\n",
    "def load_equity_data(file_path):\n",
    "    df = pd.read_csv(file_path, parse_dates=['Timestamp'], dayfirst=True)\n",
    "    df['logS'] = np.log(df['LTP'].replace(0, np.nan)).fillna(method='ffill')\n",
    "    df['Time'] = (df['Timestamp'] - df['Timestamp'].min()).dt.total_seconds()\n",
    "    df['Time'] = df['Time'] / df['Time'].max()\n",
    "\n",
    "    df['Return'] = np.log(df['LTP'] / df['LTP'].shift(1)).fillna(0)\n",
    "    df['Entropy'] = (df['Return']**2).rolling(5).mean().fillna(0)\n",
    "    df['Volume'] = df['LTQ'].fillna(0)\n",
    "    df['RegimeFlag'] = ((df['Return'].abs() > 0.01) | (df['Entropy'] > 0.0005)).astype(int)\n",
    "\n",
    "    # --- Enhanced Im(Ïˆ): Signed smoothed entropy ---\n",
    "    signed_entropy = np.sign(df['Return']) * df['Entropy']\n",
    "    im_psi = signed_entropy.ewm(span=10, adjust=False).mean()\n",
    "    im_psi = np.tanh(im_psi / (im_psi.std() + 1e-8))  # bounded for smoothness\n",
    "\n",
    "    df['ImPsi'] = im_psi\n",
    "    return df\n",
    "\n",
    "def create_equity_mat():\n",
    "    eqt_df = load_equity_data(EQT_TRAIN_FILE)\n",
    "\n",
    "    x = eqt_df['logS'].values\n",
    "    t = eqt_df['Time'].values\n",
    "    re_psi = eqt_df['LTP'].values\n",
    "    im_psi = eqt_df['ImPsi'].values\n",
    "    uu = re_psi + 1j * im_psi\n",
    "\n",
    "    feature_dict = {\n",
    "        'Entropy': eqt_df['Entropy'].values,\n",
    "        'Volume': eqt_df['Volume'].values,\n",
    "        'RegimeFlag': eqt_df['RegimeFlag'].values,\n",
    "    }\n",
    "\n",
    "    x_grid = np.linspace(np.min(x), np.max(x), 256)\n",
    "    t_grid = np.linspace(np.min(t), np.max(t), 100)\n",
    "    x_mesh, t_mesh = np.meshgrid(x_grid, t_grid)\n",
    "    uu_grid = griddata((x, t), uu, (x_mesh, t_mesh), method='linear', fill_value=0)\n",
    "\n",
    "    feature_grids = {\n",
    "        name: griddata((x, t), val, (x_mesh, t_mesh), method='linear', fill_value=0)\n",
    "        for name, val in feature_dict.items()\n",
    "    }\n",
    "\n",
    "    output = {\n",
    "        'x': x_grid,\n",
    "        'tt': t_grid,\n",
    "        'uu': uu_grid,\n",
    "    }\n",
    "    output.update(feature_grids)\n",
    "\n",
    "    sio.savemat(EQT_OUTPUT_MAT_FILE, output)\n",
    "    print(f\".mat file saved: {EQT_OUTPUT_MAT_FILE}\")\n",
    "    return EQT_OUTPUT_MAT_FILE.name, list(output.keys())\n",
    "\n",
    "# Run\n",
    "if __name__ == \"__main__\":\n",
    "    create_equity_mat()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.io import savemat\n",
    "from scipy.stats import norm\n",
    "from scipy.interpolate import griddata, SmoothBivariateSpline\n",
    "import os\n",
    "\n",
    "# === CONFIGURATION ===\n",
    "OPTION_CSV = \"OPT_RELIANCE_20250626.csv\"\n",
    "EXPIRY = \"20250626\"\n",
    "SYMBOL = \"RELIANCE\"\n",
    "KERNEL_SMOOTH = 3  # for smoothing returns\n",
    "GAP_THRESHOLD = 5\n",
    "ENTROPY_WINDOW = 15\n",
    "\n",
    "# === BLACK-SCHOLES HELPER ===\n",
    "def bs_delta(S, K, T, r, sigma, option_type='C'):\n",
    "    d1 = (np.log(S/K) + (r + 0.5*sigma**2)*T) / (sigma*np.sqrt(T))\n",
    "    if option_type == 'C':\n",
    "        return norm.cdf(d1)\n",
    "    else:\n",
    "        return -norm.cdf(-d1)\n",
    "\n",
    "def bs_iv_call(S, K, T, r, market_price, tol=1e-5, max_iter=100):\n",
    "    from scipy.optimize import brentq\n",
    "    def bs_price(sigma):\n",
    "        d1 = (np.log(S/K) + (r + 0.5*sigma**2)*T) / (sigma*np.sqrt(T))\n",
    "        d2 = d1 - sigma*np.sqrt(T)\n",
    "        return S * norm.cdf(d1) - K * np.exp(-r*T) * norm.cdf(d2)\n",
    "    try:\n",
    "        return brentq(lambda sigma: bs_price(sigma) - market_price, 1e-6, 5.0, maxiter=max_iter)\n",
    "    except Exception:\n",
    "        return np.nan\n",
    "\n",
    "# === LOAD & PREPROCESS DATA ===\n",
    "df = pd.read_csv(OPTION_CSV)\n",
    "df.dropna(subset=['LTP', 'BuyPrice', 'OpenInterest', 'StrikePrice', 'DTE'], inplace=True)\n",
    "df['Timestamp'] = pd.to_datetime(df['Timestamp'])\n",
    "df['MidPrice'] = 0.5 * (df['BuyPrice'] + df['SellPrice'])\n",
    "\n",
    "# === GRID CREATION ===\n",
    "x_vals = np.sort(df['StrikePrice'].unique())\n",
    "tt_vals = np.sort(df['DTE'].unique()) / df['DTE'].max()\n",
    "Nx, Nt = len(x_vals), len(tt_vals)\n",
    "\n",
    "# === SURFACE CONSTRUCTION ===\n",
    "grid_df = df.copy()\n",
    "grid_df['x'] = grid_df['StrikePrice']\n",
    "grid_df['t'] = grid_df['DTE'] / df['DTE'].max()\n",
    "grid_df['log_moneyness'] = np.log(df['Underlying'].astype(float) / df['StrikePrice'].astype(float))\n",
    "pivot_ltp = grid_df.pivot(index='DTE', columns='StrikePrice', values='LTP').fillna(0)\n",
    "pivot_mid = grid_df.pivot(index='DTE', columns='StrikePrice', values='MidPrice').fillna(0)\n",
    "uu_real = pivot_ltp.values\n",
    "uu_imag = pivot_ltp.pct_change().rolling(KERNEL_SMOOTH, axis=0).mean().fillna(0).values\n",
    "\n",
    "# === MASK ===\n",
    "mask = (uu_real > 0).astype(int)\n",
    "\n",
    "# === ENGINEERED FEATURES ===\n",
    "oi = grid_df.pivot(index='DTE', columns='StrikePrice', values='OpenInterest').fillna(0).values\n",
    "entropy = np.log(1 + np.abs(pivot_ltp.pct_change().rolling(ENTROPY_WINDOW, axis=0).std())).fillna(0).values\n",
    "vol_shock = (entropy > np.nanpercentile(entropy, 85)).astype(int)\n",
    "gap_open = (pivot_ltp - pivot_mid > GAP_THRESHOLD).astype(int)\n",
    "event_day = grid_df.groupby('DTE')['Timestamp'].transform(lambda x: x.duplicated()).values.reshape(Nt, Nx).astype(int)\n",
    "\n",
    "# === DELTA & IV ===\n",
    "r = 0.05\n",
    "delta = np.zeros((Nt, Nx))\n",
    "iv = np.zeros((Nt, Nx))\n",
    "for i, t in enumerate(np.sort(df['DTE'].unique())):\n",
    "    for j, k in enumerate(x_vals):\n",
    "        row = df[(df['DTE'] == t) & (df['StrikePrice'] == k)]\n",
    "        if not row.empty:\n",
    "            S = row['Underlying'].values[0]\n",
    "            T = t / 365\n",
    "            try:\n",
    "                market_price = row['LTP'].values[0]\n",
    "                iv[i, j] = bs_iv_call(S, k, T, r, market_price)\n",
    "                delta[i, j] = bs_delta(S, k, T, r, iv[i, j])\n",
    "            except Exception:\n",
    "                iv[i, j] = np.nan\n",
    "                delta[i, j] = np.nan\n",
    "iv = np.nan_to_num(iv, nan=0.0)\n",
    "delta = np.nan_to_num(delta, nan=0.0)\n",
    "\n",
    "# === FEATURES TENSOR ===\n",
    "features = np.stack([oi, entropy, vol_shock, gap_open, event_day, iv, delta], axis=2)\n",
    "\n",
    "# === SAVE TO .mat ===\n",
    "savemat(f'PINN_TRAIN_DATA_{EXPIRY}.mat', {\n",
    "    'x': x_vals,\n",
    "    'tt': tt_vals,\n",
    "    'uu': uu_real + 1j * uu_imag,\n",
    "    'features': features,\n",
    "    'mask': mask,\n",
    "    'symbol': SYMBOL,\n",
    "    'expiry': EXPIRY\n",
    "})\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "1dSE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
